{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f778365",
   "metadata": {},
   "source": [
    "## Fitting S_E Mean to 0.164 using default RWW Parameters\n",
    "\n",
    "What is being modeled:\n",
    "* Created a Sphere'd Cube (chosen points on cube projected onto radius = 1 sphere), so that regions were more evently distributed. All corners of cube chosen as regions, thus there are 8 regions. \n",
    "* EEG channels located on the center of each face of the cube. Thus there are 6 EEG channels.\n",
    "* Added some randomness to initial values - to decorrelate the signals a bit. Looking for FC matrix to look similar to SC matrix.\n",
    "\n",
    "\n",
    "## Was able to run 30 seconds of simulation with backward graph!\n",
    "\n",
    "That is, it was able to run 30 seconds of simulation mostly in RAM (SSD was running a bit) vs. before about 2-3 second could be run in 16 GB RAM laptop (but with the additional Objective Function Running, and not wiping sim results at end of loop). \n",
    "\n",
    "However, it has to be done in 300 chunks of 0.1 seconds in parallel. This will impact learning ability. Also, will require an initial pass of forward function without gradients to find the 300 initial conditions.\n",
    "\n",
    "So basically, a 10x decrease in RAM usage (might also be helped wiping memory on each loop, and not running Objective Function). That said, based on other tests I did the memory benefit might not be as great for larger networks with more nodes - possibly because the tensors would already be a bigger size. \n",
    "\n",
    "UPDATE: Actually I think i was running 300 chunks of 1 seconds!\n",
    "\n",
    "\n",
    "## Next to show running in blocks produce same as running in series\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f89fac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from whobpyt.models import RNNJANSEN,ParamsJR,RNNWWD,RWW_Layer,RWW_Params,BOLD_Layer,BOLD_Params,EEG_Layer,EEG_Params,Jansen_Layer\n",
    "\n",
    "from whobpyt.objective import meanVariableLoss,powerSpectrumLoss,functionalConnectivityLoss\n",
    "\n",
    "from whobpyt.fit import Model_fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5abff038",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05a4577f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = psutil.Process(os.getpid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f53a2d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "## Defining Model Parameters\n",
    "#############################################\n",
    "\n",
    "num_regions = 8\n",
    "num_channels = 6\n",
    "\n",
    "# Simulation Length\n",
    "step_size = 0.1 # Step Size in msecs\n",
    "sim_len = 100 # Simulation length in msecs\n",
    "sim_dim = 10\n",
    "\n",
    "skip_trans = int(500/step_size)\n",
    "\n",
    "# Initial Conditions\n",
    "S_E = 0.6; S_I = 0.1; x = 0.0000; f = 2.4286; v = 1.3283; q = 0.6144 # x,f,v,q might be choosen for different initial S_E\n",
    "init_state = torch.tensor([[S_E], [S_I], [x], [f], [v], [q]]).repeat(num_regions, 1, sim_dim)\n",
    "\n",
    "# Add randomness\n",
    "#init_state = init_state + torch.randn_like(init_state)/30 # Randomizing initial values\n",
    "\n",
    "# Create a RWW Params\n",
    "paramsNode = RWW_Params(num_regions)\n",
    "\n",
    "#Create #EEG Params\n",
    "paramsEEG = EEG_Params(torch.eye(num_regions))\n",
    "\n",
    "#Create BOLD Params\n",
    "paramsBOLD = BOLD_Params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ed8888c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 6, 10])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcf7b992",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "## Further Adjusting Parameters for Network\n",
    "#############################################\n",
    "\n",
    "paramsNode.J = torch.nn.Parameter(0.15  * torch.ones(num_regions,1)) #This is a parameter that will be updated during training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f7fff1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paramsNode.J.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba1c59d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "## Generating a physically possible (in 3D Space) Structural Connectivity Matrix\n",
    "#############################################\n",
    "\n",
    "# First, get corner points on a cube and project onto a sphere\n",
    "square_points = torch.tensor([[1.,1.,1.],\n",
    "                              [-1.,1.,1.],\n",
    "                              [1.,-1.,1.],\n",
    "                              [-1.,-1.,1.],\n",
    "                              [1.,1.,-1.],\n",
    "                              [-1.,1.,-1.],\n",
    "                              [1.,-1.,-1.],\n",
    "                              [-1.,-1.,-1.]])\n",
    "sphere_points = square_points / torch.sqrt(torch.sum(torch.square(square_points), axis = 1)).repeat(3, 1).t()\n",
    "\n",
    "# Second, find the distance between all pairs of points\n",
    "dist_mtx = torch.zeros(num_regions, num_regions)\n",
    "for x in range(num_regions):\n",
    "    for y in range(num_regions):\n",
    "        dist_mtx[x,y]= torch.linalg.norm(sphere_points[x,:] - sphere_points[y,:])\n",
    "\n",
    "# Third, Structural Connectivity defined to be 1/dist and remove self-connection values\n",
    "SC_mtx = 1/dist_mtx\n",
    "for z in range(num_regions):\n",
    "    SC_mtx[z,z] = 0.0\n",
    "\n",
    "# Fourth, Normalize the matrix\n",
    "SC_mtx_norm = (1/torch.linalg.matrix_norm(SC_mtx, ord = 2)) * SC_mtx\n",
    "Con_Mtx = SC_mtx_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b15143a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'SC of Artificial Data')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(max(abs(torch.linalg.eig(SC_mtx_norm).eigenvalues)))\n",
    "mask = np.eye(num_regions)\n",
    "sns.heatmap(Con_Mtx, mask = mask, center=0, cmap='RdBu_r', vmin=-0.1, vmax = 0.25)\n",
    "plt.title(\"SC of Artificial Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37a9f859",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "## Generating a Lead Field Matrix\n",
    "#############################################\n",
    "\n",
    "# Placing an EEG Electrode in the middle of each cube face. \n",
    "# Then electrode is equally distance from four courner on cube face squre.\n",
    "# Assume no signal from further four points. \n",
    "\n",
    "Lead_Field = torch.tensor([[1,1,0,0,1,1,0,0],\n",
    "                           [1,1,1,1,0,0,0,0],\n",
    "                           [0,1,0,1,0,1,0,1],\n",
    "                           [0,0,0,0,1,1,1,1],\n",
    "                           [1,0,1,0,1,0,1,0],\n",
    "                           [0,0,1,1,0,0,1,1]], dtype = torch.float)\n",
    "LF_Norm = (1/torch.linalg.matrix_norm(Lead_Field, ord = 2)) * Lead_Field\n",
    "\n",
    "paramsEEG.LF = LF_Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0b619ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "## Generating a \"Connectivity Matrix\" for Channel Space\n",
    "#############################################\n",
    "\n",
    "## Generating a physically possible (in 3D Space) \"Channel\" Connectivity Matrix\n",
    "# That is a theoretical matrix for the EEG SC to be fit to\n",
    "\n",
    "# First, get face points on a cube and project onto a sphere\n",
    "LF_square_points = torch.tensor([[0.,1.,0.],\n",
    "                                 [0.,0.,1.],\n",
    "                                 [-1.,0.,0.],\n",
    "                                 [0.,0.,-1.],\n",
    "                                 [1.,0.,0.],\n",
    "                                 [0.,-1.,0.]])\n",
    "# Note: this does nothing as the points are already on the r=1 sphere\n",
    "LF_sphere_points = LF_square_points / torch.sqrt(torch.sum(torch.square(LF_square_points), axis = 1)).repeat(3, 1).t()\n",
    "\n",
    "\n",
    "# Second, find the distance between all pairs of channel points\n",
    "LF_dist_mtx = torch.zeros(num_channels, num_channels)\n",
    "for x in range(num_channels):\n",
    "    for y in range(num_channels):\n",
    "        LF_dist_mtx[x,y]= torch.linalg.norm(LF_sphere_points[x,:] - LF_sphere_points[y,:])\n",
    "\n",
    "# Third, Structural Connectivity defined to be 1/dist and remove self-connection values\n",
    "LF_SC_mtx = 1/LF_dist_mtx\n",
    "for z in range(num_channels):\n",
    "    LF_SC_mtx[z,z] = 0.0\n",
    "\n",
    "# Fourth, Normalize the matrix\n",
    "LF_SC_mtx_norm = (1/torch.linalg.matrix_norm(LF_SC_mtx, ord = 2)) * LF_SC_mtx\n",
    "LF_Con_Mtx = LF_SC_mtx_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef6de4e",
   "metadata": {},
   "source": [
    "## Functions for \"Parallization\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10af2d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blockTS(data, blocks, numNodes, numSV):\n",
    "    # data: time x nodes x state_variables\n",
    "    # return: time x nodes x state_variables x blocks\n",
    "    \n",
    "    n = torch.numel(data)\n",
    "    \n",
    "    if (not (n%blocks == 0)):\n",
    "        print(\"ERROR: data is not divisable by blocks\")\n",
    "        return \n",
    "    \n",
    "    newTimeDim = int(n/(blocks*numNodes*numSV))\n",
    "    \n",
    "    data_p = data.permute((2,1,0)) # state_vars x nodes x time\n",
    "    data_r = torch.reshape(data_p, (numSV, numNodes, blocks, newTimeDim))\n",
    "    data_p2 = data_r.permute((3, 1, 0, 2))\n",
    "    \n",
    "    return data_p2\n",
    "    \n",
    "    \n",
    "def serializeTS(data, numNodes, numSV):\n",
    "    # data: time x nodes x state_variables x blocks\n",
    "    # return: time x nodes x state_variables\n",
    "\n",
    "    n = torch.numel(data)\n",
    "    newTimeDim = int(n/(numNodes*numSV))\n",
    "    \n",
    "    data_p = data.permute((2,1,3,0))\n",
    "    data_r = torch.reshape(data_p, (numSV, numNodes, newTimeDim))\n",
    "    data_p2 = data_r.permute((2,1,0))\n",
    "    \n",
    "    return data_p2\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ccf617",
   "metadata": {},
   "source": [
    "## Defining the CNMM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97aa7c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The Multi-Modal Model\n",
    "\n",
    "class mmModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(mmModel, self).__init__()\n",
    "        \n",
    "        self.nodes = RWW_Layer(num_regions, sim_dim, paramsNode, Con_Mtx, dist_mtx, step_size)\n",
    "        self.eeg = EEG_Layer(num_regions, sim_dim, paramsEEG, num_channels)\n",
    "        self.bold = BOLD_Layer(num_regions, sim_dim, paramsBOLD)\n",
    "        \n",
    "        self.next_start_state = init_state\n",
    "        \n",
    "    def forward(self, sim_len, debug = False):\n",
    "        \n",
    "        self.step_size = step_size #in msec\n",
    "        self.sim_len = sim_len #in msec\n",
    "        \n",
    "        node_states, node_history = self.nodes.forward(self.next_start_state[:, 0:2, :], self.sim_len, debug = debug)\n",
    "        EEG_history = self.eeg.forward(self.step_size, self.sim_len, node_history)\n",
    "        BOLD_states, BOLD_history = self.bold.forward(self.next_start_state[:, 2:6, :], self.step_size, self.sim_len, node_history[:,:,0,:])\n",
    "        \n",
    "        print(node_states.shape)\n",
    "        print(BOLD_states.shape)\n",
    "        \n",
    "        self.next_start_state = torch.cat((node_states, BOLD_states), dim=1).detach()\n",
    "        \n",
    "        return node_history, EEG_history, BOLD_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c662ef29",
   "metadata": {},
   "source": [
    "## Defining the Objective Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49a40f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Written in such as way as to be able to adjust the relative importance of components that make up the objective function.\n",
    "## Also, written in such a way as to be able to track and plot indiviual components losses over time. \n",
    "\n",
    "class objectiveFunction():\n",
    "    def __init__(self):\n",
    "        # Weights of Objective Function Components\n",
    "        self.S_E_mean_weight = 1\n",
    "        self.S_I_mean_weight = 0 # Not Currently Used\n",
    "        self.EEG_PSD_weight = 0 # Not Currently Used\n",
    "        self.EEG_FC_weight = 0 # Not Currently Used\n",
    "        self.BOLD_PSD_weight = 0 # Not Currently Used\n",
    "        self.BOLD_FC_weight = 0 # Not Currently Used\n",
    "        \n",
    "        # Functions of the various Objective Function Components\n",
    "        self.S_E_mean = meanVariableLoss(num_regions, varIdx = 0, targetValue = torch.tensor([0.164]))\n",
    "        #self.S_I_mean = meanVariableLoss(...) # Not Currently Used\n",
    "        #self.EEG_PSD = powerSpectrumLoss(num_channels, varIdx = 0, sampleFreqHz = 1000*(1/step_size), targetValue = targetEEG)\n",
    "        #self.EEG_FC = functionalConnectivityLoss(...) # Not Currently Used\n",
    "        #self.BOLD_PSD = powerSpectrumLoss(...) # Not Currently Used\n",
    "        #self.BOLD_FC = functionalConnectivityLoss(num_regions, varIdx = 4, targetValue = SC_mtx_norm)\n",
    "                \n",
    "    def calcTotalLoss(self, node_history, EEG_history, BOLD_history, returnLossComponents = False):\n",
    "        \n",
    "        S_E_mean_loss = self.S_E_mean.calcLoss(node_history) \n",
    "        S_I_mean_loss = torch.tensor([0]) #self.S_I_mean.calcLoss(node_history)\n",
    "        EEG_PSD_loss = torch.tensor([0]) #self.EEG_PSD.calcLoss(EEG_history) \n",
    "        EEG_FC_loss = torch.tensor([0]) #self.EEG_FC.calcLoss(EEG_history)\n",
    "        BOLD_PSD_loss = torch.tensor([0]) #self.BOLD_PS.calcLoss(BOLD_history)\n",
    "        BOLD_FC_loss = torch.tensor([0]) #self.BOLD_FC.calcLoss(BOLD_history)\n",
    "                \n",
    "        totalLoss = self.S_E_mean_weight*S_E_mean_loss + self.S_I_mean_weight*S_I_mean_loss \\\n",
    "                  + self.EEG_PSD_weight*EEG_PSD_loss   + self.EEG_FC_weight*EEG_FC_loss \\\n",
    "                  + self.BOLD_PSD_weight*BOLD_PSD_loss + self.BOLD_FC_weight*BOLD_FC_loss\n",
    "                 \n",
    "        if returnLossComponents:\n",
    "            return totalLoss, (S_E_mean_loss.item(), S_I_mean_loss.item(), EEG_PSD_loss.item(), EEG_FC_loss.item(), BOLD_PSD_loss.item(), BOLD_FC_loss.item())\n",
    "        else:\n",
    "            return totalLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50122037",
   "metadata": {},
   "source": [
    "## Training The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e1d3cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mmModel()\n",
    "TotalLossFn = objectiveFunction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81f14623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('nodes.J', Parameter containing:\n",
      "tensor([[0.1500],\n",
      "        [0.1500],\n",
      "        [0.1500],\n",
      "        [0.1500],\n",
      "        [0.1500],\n",
      "        [0.1500],\n",
      "        [0.1500],\n",
      "        [0.1500]], requires_grad=True))]\n"
     ]
    }
   ],
   "source": [
    "print(list(model.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b508bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "441b3f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 6, 10])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.next_start_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9925a92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.next_start_state = model.next_start_state[:,:,(sim_dim-2):(sim_dim - 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "429fdda2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6000],\n",
       "         [0.1000],\n",
       "         [0.0000],\n",
       "         [2.4286],\n",
       "         [1.3283],\n",
       "         [0.6144]],\n",
       "\n",
       "        [[0.6000],\n",
       "         [0.1000],\n",
       "         [0.0000],\n",
       "         [2.4286],\n",
       "         [1.3283],\n",
       "         [0.6144]],\n",
       "\n",
       "        [[0.6000],\n",
       "         [0.1000],\n",
       "         [0.0000],\n",
       "         [2.4286],\n",
       "         [1.3283],\n",
       "         [0.6144]],\n",
       "\n",
       "        [[0.6000],\n",
       "         [0.1000],\n",
       "         [0.0000],\n",
       "         [2.4286],\n",
       "         [1.3283],\n",
       "         [0.6144]],\n",
       "\n",
       "        [[0.6000],\n",
       "         [0.1000],\n",
       "         [0.0000],\n",
       "         [2.4286],\n",
       "         [1.3283],\n",
       "         [0.6144]],\n",
       "\n",
       "        [[0.6000],\n",
       "         [0.1000],\n",
       "         [0.0000],\n",
       "         [2.4286],\n",
       "         [1.3283],\n",
       "         [0.6144]],\n",
       "\n",
       "        [[0.6000],\n",
       "         [0.1000],\n",
       "         [0.0000],\n",
       "         [2.4286],\n",
       "         [1.3283],\n",
       "         [0.6144]],\n",
       "\n",
       "        [[0.6000],\n",
       "         [0.1000],\n",
       "         [0.0000],\n",
       "         [2.4286],\n",
       "         [1.3283],\n",
       "         [0.6144]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.nodes.num_dim = 1\n",
    "model.eeg.num_dim = 1\n",
    "model.bold.num_dim = 1\n",
    "model.next_start_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c9a7393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 2, 1])\n",
      "torch.Size([8, 4, 1])\n"
     ]
    }
   ],
   "source": [
    "node_history, EEG_history, BOLD_history = model.forward(sim_len*sim_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3fc54e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.8443],\n",
       "         [0.1091],\n",
       "         [0.1628],\n",
       "         [2.5195],\n",
       "         [1.3399],\n",
       "         [0.6108]],\n",
       "\n",
       "        [[0.8642],\n",
       "         [0.1192],\n",
       "         [0.1637],\n",
       "         [2.5205],\n",
       "         [1.3401],\n",
       "         [0.6107]],\n",
       "\n",
       "        [[0.8511],\n",
       "         [0.1109],\n",
       "         [0.1640],\n",
       "         [2.5197],\n",
       "         [1.3400],\n",
       "         [0.6108]],\n",
       "\n",
       "        [[0.8467],\n",
       "         [0.1076],\n",
       "         [0.1642],\n",
       "         [2.5196],\n",
       "         [1.3399],\n",
       "         [0.6108]],\n",
       "\n",
       "        [[0.8544],\n",
       "         [0.1113],\n",
       "         [0.1619],\n",
       "         [2.5189],\n",
       "         [1.3399],\n",
       "         [0.6108]],\n",
       "\n",
       "        [[0.8341],\n",
       "         [0.1081],\n",
       "         [0.1627],\n",
       "         [2.5206],\n",
       "         [1.3401],\n",
       "         [0.6107]],\n",
       "\n",
       "        [[0.8219],\n",
       "         [0.1061],\n",
       "         [0.1621],\n",
       "         [2.5192],\n",
       "         [1.3399],\n",
       "         [0.6108]],\n",
       "\n",
       "        [[0.8312],\n",
       "         [0.1045],\n",
       "         [0.1623],\n",
       "         [2.5194],\n",
       "         [1.3399],\n",
       "         [0.6108]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.next_start_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "337de224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 8, 2, 1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_history.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43a859c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 8, 2, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_history[(int(sim_len/step_size)-1)::int(sim_len/step_size)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ee370cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_IC = node_history[(int(sim_len/step_size)-1)::int(sim_len/step_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd09b1bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 8, 5, 1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BOLD_history.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5477619c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 8, 4, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BOLD_history[(int(sim_len/step_size)-1)::int(sim_len/step_size),:,0:4,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "698371f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "BOLD_IC = BOLD_history[(int(sim_len/step_size)-1)::int(sim_len/step_size),:,0:4,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2f07394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ICs = torch.cat((node_IC, BOLD_IC), dim = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "482196fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 8, 6, 1])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ICs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e026dd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "ICs = torch.reshape(ICs.permute((1,2,3,0)), (8,6,sim_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "876a6c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 6, 10])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ICs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2fbbba74",
   "metadata": {},
   "outputs": [],
   "source": [
    "ICs = torch.cat((model.next_start_state, ICs), dim = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d3e8ce81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 6, 11])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ICs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "07eb71d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "newICs = ICs[:,:,0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7227d518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 6, 10])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newICs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "16b4ee28",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.next_start_state = newICs\n",
    "model.nodes.num_dim = sim_dim\n",
    "model.eeg.num_dim = sim_dim\n",
    "model.bold.num_dim = sim_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "87b492e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 2, 10])\n",
      "torch.Size([8, 4, 10])\n"
     ]
    }
   ],
   "source": [
    "node_history, EEG_history, BOLD_history = model.forward(sim_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f5c94227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 6, 10])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.next_start_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b4fcff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1661f123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check - not valid until making the noise the same\n",
    "torch.equal(torch.cat((node_history[-1,:,:,-1], BOLD_history[-1,:,0:4,-1]), dim = 1), ICs[:,:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2814e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d88e1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ee8d23",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "LossComp = list()\n",
    "\n",
    "J_values = list()\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "for i in range(epochs):\n",
    "    print(i)\n",
    "    \n",
    "    # Forward in serial no gradients\n",
    "    # Purpose to get initial conditions\n",
    "    #\n",
    "    model.next_start_state = model.next_start_state[:,:,(sim_dim-2):(sim_dim - 1)]\n",
    "    model.nodes.num_dim = 1\n",
    "    model.eeg.num_dim = 1\n",
    "    model.bold.num_dim = 1\n",
    "    node_history, EEG_history, BOLD_history = model.forward()\n",
    "    \n",
    "    print(\"Serial Finished\")\n",
    "    \n",
    "    # Forward in \"Parallel\" with Gradients\n",
    "    # Using initial conditions acquired for serial run and with the same noise\n",
    "    #\n",
    "    model.next_start_state = newICs\n",
    "    model.nodes.num_dim = sim_dim\n",
    "    model.eeg.num_dim = sim_dim\n",
    "    model.bold.num_dim = sim_dim\n",
    "    node_history, EEG_history, BOLD_history = model.forward()\n",
    "    \n",
    "    node_history = serializeTS(node_history, 8, 2)\n",
    "    EEG_history = serializeTS(EEG_history, 8, 1)\n",
    "    BOLD_history = serializeTS(BOLD_history, 8, 4 + 1)\n",
    "    \n",
    "    print(\"Blocked Finished\")\n",
    "    \n",
    "    #\n",
    "    ## Run Backpropagaion through each time block (which have a missing connection between them)\n",
    "    #\n",
    "    totalLoss, lossComponents = TotalLossFn.calcTotalLoss(node_history[skip_trans:,:,:], EEG_history[skip_trans:,:,:], BOLD_history[skip_trans:,:,:], returnLossComponents = True)\n",
    "    print(\"totalLoss = \", totalLoss.item())\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    totalLoss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    #\n",
    "    ## Tracking the performance over traning epochs\n",
    "    #\n",
    "    LossComp.append(lossComponents)\n",
    "    J_values.append(torch.flatten(model.nodes.J).detach().clone().numpy())\n",
    "    #print(\"J values = \", torch.flatten(model.nodes.J).detach().clone().numpy())\n",
    "    \n",
    "    # This is to reduce the max memory used by the program\n",
    "    if (i < (epochs - 1)):\n",
    "        node_history, EEG_history, BOLD_history = None, None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8bbab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(LossComp)\n",
    "plt.title(\"Total Loss over Training Epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f514602d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(J_values)\n",
    "plt.title(\"J_{i} Values Changing Over Training Epochs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b96ffe",
   "metadata": {},
   "source": [
    "### Plots of S_E and S_I After Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aad7f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (16, 8))\n",
    "plt.title(\"S_E and S_I\")\n",
    "for n in range(num_regions):\n",
    "    plt.plot(node_history.detach()[:,n,0], label = \"S_E Node = \" + str(n))\n",
    "    plt.plot(node_history.detach()[:,n,1], label = \"S_I Node = \" + str(n))\n",
    "\n",
    "plt.xlabel('Time Steps (multiply by step_size to get msec), step_size = ' + str(step_size))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf86c2d7",
   "metadata": {},
   "source": [
    "### Plots of EEG PSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc09fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleFreqHz = 1000*(1/step_size)\n",
    "sdAxis, sdValues = powerSpectrumLoss.calcPSD(EEG_history[skip_trans:,:,0], sampleFreqHz, minFreq = 2, maxFreq = 40)\n",
    "sdAxis_dS, sdValues_dS = powerSpectrumLoss.downSmoothPSD(sdAxis, sdValues, 32)\n",
    "sdAxis_dS, sdValues_dS_scaled = powerSpectrumLoss.scalePSD(sdAxis_dS, sdValues_dS)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(sdAxis_dS, sdValues_dS_scaled.detach())\n",
    "plt.xlabel('Hz')\n",
    "plt.ylabel('PSD')\n",
    "plt.title(\"Simulated EEG PSD: After Training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f78327c",
   "metadata": {},
   "source": [
    "### Plots of BOLD FC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9690ba05",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(BOLD_history[skip_trans:, :, 4].shape)\n",
    "sim_FC = functionalConnectivityLoss.calcFC(BOLD_history[:, :, 4]).detach()\n",
    "\n",
    "plt.figure(figsize = (8, 8))\n",
    "plt.title(\"Simulated BOLD FC: After Training\")\n",
    "mask = np.eye(num_regions)\n",
    "sns.heatmap(sim_FC, mask = mask, center=0, cmap='RdBu_r', vmin=-1.0, vmax = 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f00e50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
